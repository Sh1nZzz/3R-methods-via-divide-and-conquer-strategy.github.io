<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
    <link rel="stylesheet" type="text/css" href="ICRAv1.css">
    <style>
        @media screen and (max-width: 800px) {
            .leftcolumn, .rightcolumn {
                width: 100%;
                padding: 0;
            }
        }

        /* 响应式布局 -屏幕尺寸小于 400px 时，导航等布局改为上下布局 */
        @media screen and (max-width: 400px) {
            .guide_a a {
                float: none;
                width: 100%;
            }
        }

        a.LinkToV1 {
            color: blue;
            font-weight: 200;
        }

        /* 设置视频样式 */
        video {
            width: 100%; /* 视频宽度占据容器的100% */
            height: auto; /* 根据宽度自动调整高度 */
        }

        div.Div {
            color: black;
            width: 800px;
            margin: auto auto auto auto;
            padding: 20px;
            text-align: justify;
        }

        div.Div-down {
            color: black;
            width: 800px;
            margin: auto auto auto auto;
            padding: 25px;
            text-align: justify;
        }

        div.Div-Title {
            color: black;
            width: 800px;
            margin: auto auto auto auto;
            padding: 0px;
            text-align: left;
            font-size: 25px;
            font-weight: 400;
        }

        div.Div-Table {
            color: black;
            width: 800px;
            margin: auto auto auto auto;
            padding: 5px;
            text-align: center;
        }

        td.Table-Image {
            text-align: center; /* 水平居中 */
            vertical-align: middle; /* 垂直居中 */
        }

        /*仅对于重建表格*/
        #recon-table td:first-child {
            border-right: 2px solid black;
        }
    </style>

    <title>
        Surveys on feed-forward 3R methods for high-resolution photogrammetric images via image divide-and-conquer strategy
    </title>
</head>
<body>
    <!-- 头部导航栏 -->
    <ul class="HeadMenu">
        <li class="HeadMenu_Content"><a class="LinkTo" href="#Abstract">Abstract</a></li>
        <li class="HeadMenu_Content"><a class="LinkTo" href="#Download">Download</a></li>
        <li class="HeadMenu_Content"><a class="LinkTo" href="#Experiments">Experiments</a></li>
        <li class="HeadMenu_Content"><a class="LinkTo" href="#Acknowledgement">Acknowledgement</a></li>
        <li class="HeadMenu_Content"><a class="LinkTo" href="#About us">About us</a></li>
    </ul>

    <!-- 占位符 -->
    <div class="Empty_50"></div>

    <!-- 主标题 -->
    <div class="HeadWord">
        <!-- 占位符 -->
        <div class="Empty_50"></div>
        Surveys on feed-forward 3R methods for high-resolution photogrammetric images via image divide-and-conquer strategy
        <!-- 占位符 -->
        <div class="Empty_50"></div>
    </div>

    <div class="HeadWordName">
        Zhe Shen, Mengmeng Shu, Guanbo Wang, Yifei Yu<sup>*</sup>, Zongqian Zhan, Xin Wang
        <!-- 占位符 -->
        <div class="Empty_20"></div>
        <em>School of Geodesy and Geomatics, Wuhan University, Wuhan, P.R.China</em>
    </div>

    <!-- 占位符 -->
    <div class="Empty_20"></div>

    <!-- Overview -->
	<div class="WhitePart" style="display: flex; flex-direction: column; align-items: center; margin: 2em 0;">
		<img src="pipeline.png" alt="Overall Pipeline" style="max-width: 60%; height: auto;">
		<p style="margin-top: 0.5em; text-align: center;">Pipeline of the proposed image divide-and-conquer framework</p>
	</div>

    <!-- Abstract -->
    <div class="WhitePart">
        <div class="MainText_Title"><br><section id="Abstract">Abstract</section></div>
    </div>
    <div class="Div">
        Recently, data-driven feed-forward 3D reconstruction methods, such as DUSt3R, MASt3R, Fast3R and VGGT, have gained widespread attention due to their superior end-to-end processing capabilities across various geometric 3D vision tasks. However, heavy reliance on GPU hardwares limits the applicability of these 3R methods to only single-image pairs or small-scale datasets, making them challenging to handle large-scale high-resolution photogrammetric images. In this work, we conduct a survey on these 3R methods and employ a divide-and-conquer framework that divides the entire image dataset into several overlapping sub-blocks, reconstructs each sub-block separately using 3R methods, and then merges them per 3D similarity transformations. Experimental results demonstrate that our method effectively expands the number of images that the aforementioned feed-forward 3R methods can handle. Furthermore, a comprehensive experiment on photogrammetric data is carried out by comparing the processing time, GPU memory usage, and accuracy to explore the possibility of applying these novel feed-forward 3R methods to high-resolution photogrammetric datasets.
    </div>

    <!-- Download -->
    <div class="WhitePart">
        <div class="MainText_Title"><br><section id="Download">Download</section></div>
        <br>
    </div>

    <div class="Div">
        <table>
            <tr>
                <td colspan="5"><a href="Surveys on feed-forward 3R methods for high-resolution photogrammetric images via image.pdf" color="blue">Paper(PDF)</a></td>
            </tr>
            <tr>
                <td colspan="5"><a href="https://github.com/Sh1nZzz/3R-methods-via-divide-and-conquer-strategy" color="blue">Code(github)</a></td>
            </tr>
        </table>
    </div>

    <!-- 占位符 -->
    <div class="Empty_50"></div>

    <!-- Experiments -->
    <div class="WhitePart">
        <div class="MainText_Title"><section id="Experiments">Experiments</section></div>
    </div>
    <div class="Div">
        <br><br>
        All experiments are run on the machine with a single NVIDIA <b>RTX4090 GPU</b>.
    </div>

    <!-- Datasets -->
    <div class="Div-Title">
        1.Datasets<hr>
    </div>

    <div class="Div">
        All the datasets used in our experiments are shown in the following Table:
        <br>
    </div>

<div class="WhitePart">
  <table border="1" class="Table">
    <tr>
      <td class="Experiments">Dataset name</td>
      <td class="Experiments">Image number</td>
      <td class="Experiments">Ordered/Disordered</td>
      <td class="Experiments">Number of cameras</td>
      <td class="Experiments">Data type</td>
      <td class="Experiments">Image resolution</td>
    </tr>
    <tr>
      <td class="Experiments">XHSD</td>
      <td class="Experiments">400</td>
      <td class="Experiments">Ordered</td>
      <td class="Experiments">1</td>
      <td class="Experiments">UAV</td>
      <td class="Experiments">5472×3648</td>
    </tr>
    <tr>
      <td class="Experiments">YD</td>
      <td class="Experiments">291</td>
      <td class="Experiments">Disordered</td>
      <td class="Experiments">5</td>
      <td class="Experiments">UAV</td>
      <td class="Experiments">6000×4000</td>
    </tr>
    <tr>
      <td class="Experiments">Caffe</td>
      <td class="Experiments">287</td>
      <td class="Experiments">Disordered</td>
      <td class="Experiments">3</td>
      <td class="Experiments">close-range</td>
      <td class="Experiments">1920×1980</td>
    </tr>
  </table>
</div>



    <!-- 2.	Performance of 3R methods on single sub-block -->
    <div class="Div-Title">
        <br>2.Performance of 3R methods on single sub-block<hr>
    </div>
    <div class="Div">
    To evaluate the performance of these 3R methods within one single inference, a single sub-block from caffee dataset is tested
	and their results are compared with the ground-truth point clouds from LiDAR.
        <br><br>
        Here is Individual sub-block reconstruction results.
    </div>

    <div class="Div">
        <img src="caffe_singleblock_compare_1.jpg" width="790" height="auto">
    </div>

    <!-- 3.Feasibility of the image divide-and-conquer framework -->
    <div class="Div-Title">
        <br>3.Feasibility of the image divide-and-conquer framework<hr>
    </div>
    <div class="Div">
        In order to validate the feasibility of proposed image divide-and-conquer framework, we divide the dataset XHSD into 15
		sub-blocks and perform reconstruction using COLMAP within the proposed framework. The reconstruction results obtained
		from our proposed framework are compared with those from directly applying COLMAP to the entire scene without partitioning.
        <br><br>
        Here is Colmap results with/without our divide-and-conquer strategy.
        <br>
    </div>

    <div class="Div">
        <img src="framework_test_1.png" width="755" height="auto">
    </div>


    <!-- 4.Investigation on the impact of different blocks numbers -->
    <div class="Div-Title">
        <br>4.Investigation on the impact of different blocks numbers<hr>
    </div>
    <div class="Div">
        To explore the impact of different partitioned sub-blocks number, the XHSD dataset is divided into 15, 20, and 25 sub-blocks,
		respectively. Then they are reconstructed using four 3R methods within the proposed framework in this paper. Taking the
		reconstruction result of VGGT as an example, as shown in Fig.
        <br>
    </div>

	<div class="Div">
        <img src="vggt_3dif_blocknum_compare.jpg" width="755" height="auto">
    </div>
	
	<!-- 5.Evaluation of 3R methods on image partitioning framework -->
    <div class="Div-Title">
        <br>5.Evaluation of 3R methods on image partitioning framework<hr>
    </div>
    <div class="Div">
        Based on the optimal partitioning strategy in the paper, we divided the three datasets XHSD, YD, and Caffe into 15, 12,
		and 10 sub-blocks, respectively. Using four feed-forward 3R
		methods, experiments are conducted under the proposed framework, and the reconstruction results of XHSD, YD, and Caffe
		are shown in Fig.
        <br>
    </div>

	<div class="Div">
        <img src="Reconstruction_result.png" width="755" height="auto">
    </div>
	
    <div class="Div">
        To evaluate the reconstruction results of the four 3R methods, the reconstructions generated by the
		traditional method COLMAP (well-known for its accuracy and robustness) are selected as the ground-truth for XHSD, YD and
		Caffe, comparing the 3R method results with the reference point clouds from COLMAP, the 3D spatial accuracy of the four 3R
		methods is shown in Fig.
        <br>
    </div>

	<div class="Div">
        <img src="compare_3dataset.jpg" width="755" height="auto">
    </div>
	
	<div class="Div">
        For other details, please refer to our paper.
        <br>
    </div>



    <!-- Acknowledgement -->
    <div class="WhitePart">
        <div class="MainText_Title"><br><section id="Acknowledgement">Acknowledgement</section></div>
    </div>
    <div class="Div">
        This work was jointly supported by the National Natural Science Foundation of China (42301507) and the Natural Science Foundation of Hubei Province, China (2022CFB727). 
    </div>


    <!-- About us -->
    <div class="WhitePart">
        <div class="MainText_Title"><br><section id="About us">About us</section></div>
    </div>
    <div class="WhitePart">
        <div class="Div">
            If you have any questions or advice, you can contact us via following address:
            <ul>
				<li>shenzhe@whu.edu.cn, Zhe Shen, WuHan University</li>
                <li>yfyu2020@whu.edu.cn, YiFei Yu, WuHan University</li>
                <li>zqzhan@sgg.whu.edu.cn, Zongqian Zhan, WuHan University</li>
                <li>xwang@sgg.whu.edu.cn, Xin Wang, WuHan University</li>
            </ul>
        </div>
    </div>

    <div class="WhitePart">
        <div class="Empty_50"></div>
    </div>
</body>
</html>
